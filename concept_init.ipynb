{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014c356f-bf28-4d08-862c-acd1bf4fa274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_atomistics import Project\n",
    "#from atomrdf import KnowledgeGraph, System\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf9e85d-dc9e-4ea7-bffe-e5a629ee813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from pyironflow.pyironflow import PyironFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a08f9f-036a-4987-b2f0-cd7bb8de5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node\n",
    "def CreateProject(pr_name: str, element: str):\n",
    "    pr = Project(pr_name)\n",
    "    kg1 = KnowledgeGraph()\n",
    "    kg1.enable_workflow(pr, workflow_environment='pyiron')\n",
    "    pr_kg_el = {'project': pr, 'kg': kg1, 'element': element}\n",
    "    return pr_kg_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf589b-a38e-47bf-9764-6f76ea56f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node\n",
    "def CreateSample(pr_kg_el, cubic: bool = False):\n",
    "    pr = pr_kg_el['project']\n",
    "    element = pr_kg_el['element']\n",
    "    structure = pr.create.structure.annotated_structure.bulk(element, cubic=cubic)\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ef022-0169-447f-bc41-151cb37e4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node(\"View\")\n",
    "def VisualizeStructure(structure):\n",
    "    return structure.plot3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b90bb-552a-4c52-932b-eead557f7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node(\"sample_KG\")\n",
    "def SampleKG(pr_kg_el):\n",
    "    kg1 = pr_kg_el['kg']\n",
    "    element = pr_kg_el['element']\n",
    "    eval_string = \"System.create.element.\"+element+\"(graph=kg1)\"\n",
    "    struct_el = eval(eval_string)\n",
    "    return kg1.visualise(size=(120,30),hide_types=True, layout='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190f10bf-4cf9-4ba4-8378-767e229d39b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Workflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@Workflow\u001b[39m\u001b[38;5;241m.\u001b[39mwrap\u001b[38;5;241m.\u001b[39mas_function_node\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLammpsCalcMinimize\u001b[39m(pr_kg_el, structure, job_name:\u001b[38;5;28mstr\u001b[39m, pot_list_index: \u001b[38;5;28mint\u001b[39m, f_tol: \u001b[38;5;28mfloat\u001b[39m, min_style: \u001b[38;5;28mstr\u001b[39m, del_ex_job: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, print_concept_dicts: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     pr \u001b[38;5;241m=\u001b[39m pr_kg_el[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m     job \u001b[38;5;241m=\u001b[39m pr\u001b[38;5;241m.\u001b[39mcreate\u001b[38;5;241m.\u001b[39mjob\u001b[38;5;241m.\u001b[39mLammps(job_name, delete_existing_job\u001b[38;5;241m=\u001b[39mdel_ex_job)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Workflow' is not defined"
     ]
    }
   ],
   "source": [
    "@Workflow.wrap.as_function_node\n",
    "def LammpsCalcMinimize(pr_kg_el, structure, job_name:str, pot_list_index: int, f_tol: float, min_style: str, del_ex_job: bool = False, print_concept_dicts: bool = False):\n",
    "    pr = pr_kg_el['project']\n",
    "    job = pr.create.job.Lammps(job_name, delete_existing_job=del_ex_job)\n",
    "    job.structure = structure\n",
    "    job.potential = job.list_potentials()[pot_list_index]\n",
    "    job.calc_minimize(f_tol=f_tol, style=min_style)\n",
    "    job.run()\n",
    "    \n",
    "    import os\n",
    "    os.system('conda env export | grep -v \"^prefix: \" > ' + job.project.name + '/' + job.name + '_environment.yml')\n",
    "    \n",
    "    from pyiron_base.storage.hdfio import FileHDFio\n",
    "    hdf = FileHDFio(job.project.name + '/' + job.name + '_input_structure.h5')\n",
    "    job.structure.to_hdf(hdf)\n",
    "\n",
    "    import json\n",
    "    cdict = process_lammps_job(job)\n",
    "    file_name = job.project.name + '/' + job.name + '_concept_dict.json'\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(cdict, f, indent=2)\n",
    "        \n",
    "    struct_cdict = process_structure_crystal(job)\n",
    "    struct_file_name = job.project.name + '/' + job.name + '_input_structure_concept_dict.json'\n",
    "    with open(struct_file_name, 'w') as f:\n",
    "        json.dump(struct_cdict, f, indent=2)\n",
    "        \n",
    "    if print_concept_dicts == True: \n",
    "        print(json.dumps(struct_cdict, indent=2))\n",
    "        print(json.dumps(cdict, indent=2))\n",
    "        \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d787d1a4-d5b5-466c-bdbd-d5331786d28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Workflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@Workflow\u001b[39m\u001b[38;5;241m.\u001b[39mwrap\u001b[38;5;241m.\u001b[39mas_function_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mview\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mViewStructure\u001b[39m(structure):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m structure\u001b[38;5;241m.\u001b[39mplot3d()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Workflow' is not defined"
     ]
    }
   ],
   "source": [
    "@Workflow.wrap.as_function_node(\"view\")\n",
    "def ViewStructure(structure):\n",
    "    return structure.plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5375f3c9-7fea-41c0-a277-a6af7f92da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node(\"job_KG\")\n",
    "def JobKG(pr_kg_el, job):\n",
    "    kg1 = pr_kg_el['kg']\n",
    "    kg1.add_workflow(job, workflow_environment='pyiron')\n",
    "    return kg1.visualise(workflow_view=True, hide_types=True, size=(40,20), layout='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849c459f-63a9-4cda-8d7c-332f03eeafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node(\"object\")\n",
    "def LammpsJobOpenBIS(username:str, space:str, project:str, collection:str, job, separate_input_sample: bool = True):\n",
    "    import json\n",
    "    cdict_file = job.path + '_concept_dict.json'\n",
    "    struct_cdict_file = job.path + '_input_structure_concept_dict.json'\n",
    "    try:\n",
    "        with open(cdict_file) as json_file:\n",
    "            concept_dict = json.load(json_file)\n",
    "        with open(struct_cdict_file) as json_file:\n",
    "            struct_concept_dict = json.load(json_file)\n",
    "    except:\n",
    "        concept_dict = process_lammps_job(job)\n",
    "        file_name = job.project.name + '/' + job.name + '_concept_dict.json'\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(concept_dict, f, indent=2)\n",
    "            \n",
    "        struct_concept_dict = process_structure_crystal(job)\n",
    "        struct_file_name = job.project.name + '/' + job.name + '_input_structure_concept_dict.json'\n",
    "        with open(struct_file_name, 'w') as f:\n",
    "            json.dump(struct_concept_dict, f, indent=2)\n",
    "\n",
    "    from IPython.display import display\n",
    "    if separate_input_sample == True:\n",
    "        s = GenericCrystalObject(username, space, project, collection, \"input\", struct_concept_dict)\n",
    "        j = GenericLammpsJobObject(username, space, project, collection, concept_dict, struct_concept_dict)\n",
    "        display(s)\n",
    "        display(j)\n",
    "    else:\n",
    "        j = GenericLammpsJobObject(username, space, project, collection, concept_dict)\n",
    "        display(j)\n",
    "            \n",
    "    return \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db130ef-2241-4784-87f8-c80ca8c0c857",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Workflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wf \u001b[38;5;241m=\u001b[39m \u001b[43mWorkflow\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_wf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m wf\u001b[38;5;241m.\u001b[39mProject_KG_Element \u001b[38;5;241m=\u001b[39m CreateProject(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_gui\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m wf\u001b[38;5;241m.\u001b[39mStructure \u001b[38;5;241m=\u001b[39m CreateSample(wf\u001b[38;5;241m.\u001b[39mProject_KG_Element, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Workflow' is not defined"
     ]
    }
   ],
   "source": [
    "wf = Workflow(\"test_wf\")\n",
    "\n",
    "wf.Project_KG_Element = CreateProject(\"test_gui\", \"Fe\")\n",
    "wf.Structure = CreateSample(wf.Project_KG_Element, True)\n",
    "wf.ViewStructure = ViewStructure(wf.Structure)\n",
    "#wf.SampleKG = SampleKG(wf.Project_KG_Element)\n",
    "wf.LammpsCalcMinimize = LammpsCalcMinimize(wf.Project_KG_Element, wf.Structure, \"test_lammps_gui\", 68, 1e-8, \"fire\", True, True)\n",
    "wf.JobKG = JobKG(wf.Project_KG_Element, wf.LammpsCalcMinimize)\n",
    "wf.LammpsJobOpenBIS = LammpsJobOpenBIS(\"tlakshmi\", \"TLAKSHMI\", \"TEST\", \"TEST_EXP_1\", wf.LammpsCalcMinimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62aa55d5-9a3f-4a16-90b6-3d49e7ececf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadinessError",
     "evalue": "LammpsJobOpenBIS received a run command but is not ready. The node should be neither running nor failed, and all input values should conform to type hints.\nLammpsJobOpenBIS readiness: False\nSTATE:\nrunning: False\nfailed: False\nINPUTS:\nusername ready: True\nspace ready: True\nproject ready: True\ncollection ready: True\njob ready: False\nseparate_input_sample ready: True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mReadinessError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLammpsJobOpenBIS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pyiron_wf_dev\\Lib\\site-packages\\pyiron_workflow\\node.py:751\u001b[0m, in \u001b[0;36mNode.pull\u001b[1;34m(self, run_parent_trees_too, *args, **kwargs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpull\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, run_parent_trees_too\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    A shortcut for :meth:`run` with particular flags.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m            first pull.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_data_tree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_parent_trees_too\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_parent_trees_too\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfetch_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_readiness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43memit_ran_signal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pyiron_wf_dev\\Lib\\site-packages\\pyiron_workflow\\node.py:491\u001b[0m, in \u001b[0;36mNode.run\u001b[1;34m(self, run_data_tree, run_parent_trees_too, fetch_input, check_readiness, raise_run_exceptions, emit_ran_signal, *args, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is still waiting for a serialized result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m         )\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_input_values(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_readiness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_readiness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_run_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_run_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbefore_run_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_data_tree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_data_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_parent_trees_too\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_parent_trees_too\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfetch_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memit_ran_signal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_ran_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_finally_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memit_ran_signal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_ran_signal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise_run_exceptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_run_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pyiron_wf_dev\\Lib\\site-packages\\pyiron_workflow\\mixin\\run.py:147\u001b[0m, in \u001b[0;36mRunnable.run\u001b[1;34m(self, check_readiness, raise_run_exceptions, before_run_kwargs, run_kwargs, run_exception_kwargs, run_finally_kwargs, finish_run_kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m run_finally_kwargs \u001b[38;5;241m=\u001b[39m _none_to_dict(run_finally_kwargs)\n\u001b[0;32m    145\u001b[0m finish_run_kwargs \u001b[38;5;241m=\u001b[39m _none_to_dict(finish_run_kwargs)\n\u001b[1;32m--> 147\u001b[0m stop_early, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_before_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_readiness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_readiness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbefore_run_kwargs\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_early:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pyiron_wf_dev\\Lib\\site-packages\\pyiron_workflow\\node.py:535\u001b[0m, in \u001b[0;36mNode._before_run\u001b[1;34m(self, check_readiness, run_data_tree, run_parent_trees_too, fetch_input, emit_ran_signal)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cache:  \u001b[38;5;66;03m# Write cache and continue\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mto_value_dict()\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_before_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_readiness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_readiness\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pyiron_wf_dev\\Lib\\site-packages\\pyiron_workflow\\mixin\\run.py:185\u001b[0m, in \u001b[0;36mRunnable._before_run\u001b[1;34m(self, check_readiness, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mThings to do _before_ running.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    (ReadinessError): If :param:`check_readiness` but not :attr:`ready`.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_readiness \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadinessError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readiness_error_message)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mReadinessError\u001b[0m: LammpsJobOpenBIS received a run command but is not ready. The node should be neither running nor failed, and all input values should conform to type hints.\nLammpsJobOpenBIS readiness: False\nSTATE:\nrunning: False\nfailed: False\nINPUTS:\nusername ready: True\nspace ready: True\nproject ready: True\ncollection ready: True\njob ready: False\nseparate_input_sample ready: True"
     ]
    }
   ],
   "source": [
    "wf.LammpsJobOpenBIS.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f7d82c6-e35f-484e-849e-15620af57f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure Inputs ['pr_kg_el', 'cubic'] Project_KG_Element\n",
      "ViewStructure Inputs ['structure'] Structure\n",
      "LammpsCalcMinimize Inputs ['pr_kg_el', 'structure', 'job_name', 'pot_list_index', 'f_tol', 'min_style', 'del_ex_job', 'print_concept_dicts'] Project_KG_Element\n",
      "LammpsCalcMinimize Inputs ['pr_kg_el', 'structure', 'job_name', 'pot_list_index', 'f_tol', 'min_style', 'del_ex_job', 'print_concept_dicts'] Structure\n",
      "JobKG Inputs ['pr_kg_el', 'job'] Project_KG_Element\n",
      "JobKG Inputs ['pr_kg_el', 'job'] LammpsCalcMinimize\n",
      "LammpsJobOpenBIS Inputs ['username', 'space', 'project', 'collection', 'job', 'separate_input_sample'] LammpsCalcMinimize\n"
     ]
    }
   ],
   "source": [
    "for v in wf.children.values():\n",
    "    for i in v.inputs:\n",
    "        for c in i.connections:\n",
    "            print(v.label, v.inputs, c.owner.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f4a6583-f55a-41b5-a815-626d2fa63021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf27dc88d9c04196a9ce310107551f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Accordion(children=(Tree(), Output(layout=Layout(border_bottom='1px solid black', border_left='…"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = PyironFlow([wf])\n",
    "pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbcf539c-2f17-4c40-86b1-98632ce00ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8b61a43b004387b36d967141e98ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.out_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f70ca-af04-409a-a72f-79d16495bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybis import Openbis\n",
    "o = Openbis('https://test3.datastore.bam.de/')          # https:// is assumed\n",
    "\n",
    "import getpass\n",
    "password = getpass.getpass()\n",
    "\n",
    "o.login('tlakshmi', password, save_token=True)   # save the session token in ~/.pybis/example.com.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952eb661-16ca-45c1-88b4-7a5288fb1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a09f9b70-77fe-4104-855b-4dc55bd25506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session is active: True and token is tlakshmi-241021084954275xC29AA6D810C770329B37D9F7D2D88EFE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Session is active: {o.is_session_active()} and token is {o.token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4bb37524-03db-4b94-b6e7-ed39bf059c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obis_obj = o.get_sample(\"/TLAKSHMI/TEST/TEST_EXP_1/PYI_JOB.LMP81\")\n",
    "#obis_obj.p[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "50598680-1a5b-48b2-bfbd-3cc6572f1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obis_obj.set_properties({'description': '<figure class=\"image image_resized image-style-align-left\" style=\"width:11.48%;\"><img src=\"/openbis/openbis/file-service/eln-lims/30/77/c8/3077c8f8-0e55-41e5-9021-7ed43863e5a4/cc44149e-b2d4-4850-9f88-7a4cd54c1a66.png\"></figure><p>Lammps simulation using pyiron for energy minimization/structural optimization.<br>&nbsp;</p><p><span style=\"color:hsl(240,75%,60%);\"><strong>Scroll down below other properties to view conceptual dictionary with ontological ids of selected properties and values.</strong></span></p><p>The conceptual dictionary is in JSON-LD format. Learn more about it <a href=\"https://www.w3.org/ns/json-ld/\">here</a><br>&nbsp;</p>'})\n",
    "#obis_obj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ae2757e4-436f-4a62-a8eb-bb6bbebde5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_from_gui = pf.get_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4f39e23f-542e-49c3-8a96-2ed4d66dce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Project_KG_Element', <__main__.CreateProject object at 0x7f5a73fcbd10>), ('Structure', <__main__.CreateSample object at 0x7f5a7409d110>), ('ViewStructure', <__main__.ViewStructure object at 0x7f5a73fcb5d0>), ('LammpsCalcMinimize', <__main__.LammpsCalcMinimize object at 0x7f5a73fb3390>), ('JobKG', <__main__.JobKG object at 0x7f5a73f88090>), ('LammpsJobOpenBIS', <__main__.LammpsJobOpenBIS object at 0x7f5a73fb2a50>)])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_from_gui.children.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7c6ca5de-c331-4789-bdd2-4952df37967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlakshmi/anaconda3/envs/pyiron_unify_1/lib/python3.11/site-packages/spglib/spglib.py:115: DeprecationWarning: dict interface (SpglibDataset['international']) is deprecated.Use attribute interface ({self.__class__.__name__}.{key}) instead\n",
      "  warnings.warn(\n",
      "/home/tlakshmi/anaconda3/envs/pyiron_unify_1/lib/python3.11/site-packages/spglib/spglib.py:115: DeprecationWarning: dict interface (SpglibDataset['number']) is deprecated.Use attribute interface ({self.__class__.__name__}.{key}) instead\n",
      "  warnings.warn(\n",
      "/home/tlakshmi/anaconda3/envs/pyiron_unify_1/lib/python3.11/site-packages/pyiron_atomistics/lammps/interactive.py:302: UserWarning: f_tol is deprecated as of vers. 0.3.0. It is not guaranteed to be in service in vers. 0.4.0. Use ionic_force_tolerance instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job test_lammps_gui was saved and received the ID: 49\n"
     ]
    }
   ],
   "source": [
    "obis_job = wf_from_gui.LammpsCalcMinimize.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ed431-b0df-4337-984a-de6a56708374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479aabf-a37b-43d7-9670-8e028a5adb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c693fe-1981-42d6-9293-e6b7a1770a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10679988-add6-4a73-969d-bfc2e77320f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba095fe0-138f-4325-a7d5-59b671995b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenericCrystalObject(user, space, project, collection, name_prefix, concept_dict):\n",
    "    o = Openbis('https://test3.datastore.bam.de/')\n",
    "    cdict = flatten_crystal_cdict(concept_dict)\n",
    "\n",
    "    objects = o.get_objects(\n",
    "        space      = space,\n",
    "        type       ='MAT_SIM_STRUCTURE.CRYSTAL',\n",
    "        start_with = 0,\n",
    "    )\n",
    "    exists = False\n",
    "    for object_ in objects:\n",
    "        if object_.p.get('$name') == name_prefix + '_structure_' + cdict['job_name']:\n",
    "            exists = True\n",
    "            found_object = object_\n",
    "\n",
    "    if exists == True:\n",
    "        print(\"======================\\n\")\n",
    "        print(\"Sample already exists!\\n\")\n",
    "        print(\"======================\\n\")\n",
    "        print(\"Found object properties:\\n\")\n",
    "        return found_object.p\n",
    "\n",
    "    else:\n",
    "\n",
    "        description =   '<figure class=\"image image_resized image-style-align-left\" style=\"width:9%;\">' + \\\n",
    "                        '<img src=\"/openbis/openbis/file-service/eln-lims/30/77/c8/3077c8f8-0e55-41e5-9021-7ed43863e5a4/cc44149e-b2d4-4850-9f88-7a4cd54c1a66.png\">' + \\\n",
    "                        '</figure><p><br>Crystal structure generated using pyiron.<br>&nbsp;</p><p><span style=\"color:hsl(240,75%,60%);\">' + \\\n",
    "                        '<strong>Scroll down below other properties to view conceptual dictionary with ontological ids of selected properties and values.</strong></span>' + \\\n",
    "                        '</p><p>The conceptual dictionary is in JSON-LD format. Learn more about it <a href=\"https://www.w3.org/ns/json-ld/\">here</a><br>&nbsp;</p>'\n",
    "        \n",
    "        species = {}\n",
    "        for i in concept_dict['atoms']:\n",
    "            if i['label'] != 'total_number_atoms':\n",
    "                species[i['label']] = i['value']\n",
    "\n",
    "        json_file = cdict['project_name'] + '/' + cdict['job_name'] + \"_\" + name_prefix + '_structure_concept_dict.json'\n",
    "        with open(json_file, 'r') as file:\n",
    "            json_string = file.read()\n",
    "        json_string = format_json_string(json_string)\n",
    "\n",
    "        props_dict = {\n",
    "            '$name': name_prefix + '_structure_' + cdict['job_name'],\n",
    "            'description': description,\n",
    "            'workflow_manager': cdict['workflow_manager'],\n",
    "            'chem_species_by_n_atoms': str(species),\n",
    "            'n_atoms_total': cdict['total_number_atoms'],\n",
    "            'sim_cell_lengths_in_a': cdict['simulation_cell_lengths'],\n",
    "            'sim_cell_vectors': cdict['simulation_cell_vectors'],\n",
    "            'sim_cell_angles_in_deg': cdict['simulation_cell_angles'],\n",
    "            'sim_cell_volume_in_a3': cdict['simulation_cell_volume'],\n",
    "            'conceptual_dictionary': json_string,\n",
    "        }\n",
    "\n",
    "        object_ = o.new_object(\n",
    "            type       = 'MAT_SIM_STRUCTURE.CRYSTAL',\n",
    "            space      = space,\n",
    "            experiment = '/' + space + '/' + project + '/' + collection,\n",
    "            props      = props_dict\n",
    "        )\n",
    "        object_.save()\n",
    "\n",
    "        dataset_props_dict = {\n",
    "            '$name': name_prefix + '_structure_' + cdict['job_name'] + '.h5',\n",
    "            'multi_mat_scale': 'Electronic/Atomistic',\n",
    "            'sw_compatibility': 'ASE',\n",
    "            'file_format': 'HDF5',\n",
    "        }\n",
    "        \n",
    "        path_to_h5 = cdict['project_name'] + '/' + str(cdict['job_name']) + '_input_structure.h5'\n",
    "        \n",
    "        ds_hdf = o.new_dataset(\n",
    "            type       = 'MAT_SIM_STRUCTURE',\n",
    "            collection = '/' + space + '/' + project + '/' + collection,\n",
    "            object     = object_,\n",
    "            files      = [path_to_h5],\n",
    "            props      = dataset_props_dict\n",
    "        )\n",
    "\n",
    "        ds_hdf.save()\n",
    "\n",
    "    \n",
    "    return object_.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8916595d-2ff7-4930-94d0-ef984458ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenericLammpsJobObject(user, space, project, collection, concept_dict):\n",
    "    o = Openbis('https://test3.datastore.bam.de/')\n",
    "    cdict = flatten_lammps_cdict(concept_dict)\n",
    "\n",
    "    objects = o.get_objects(\n",
    "        space      = space,\n",
    "        type       ='PYIRON_JOB.LAMMPS',\n",
    "        start_with = 0,\n",
    "    )\n",
    "    exists = False\n",
    "    for object_ in objects:\n",
    "        if object_.p.get('$name') == cdict['job_name']:\n",
    "            exists = True\n",
    "            found_object = object_\n",
    "\n",
    "    if exists == True:\n",
    "        print(\"======================\\n\")\n",
    "        print(\"Object already exists!\\n\")\n",
    "        print(\"======================\\n\")\n",
    "        print(\"Found object properties:\\n\")\n",
    "        return found_object.p\n",
    "    \n",
    "    else:\n",
    "\n",
    "        if cdict['job_status'] == 'finished':\n",
    "            job_status = True\n",
    "        else:\n",
    "            job_status = False\n",
    "\n",
    "        from datetime import datetime\n",
    "        delta = datetime.strptime(cdict['job_stoptime'], \"%Y-%m-%d %H:%M:%S\") - datetime.strptime(cdict['job_starttime'], \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        atom_calc_type = None\n",
    "        if 'molecular_statics' in concept_dict.keys() and 'minimization_algorithm' in cdict.keys():\n",
    "            atom_calc_type = ('ATOM_CALC_STRUC_OPT').lower()\n",
    "            description =   '<figure class=\"image image_resized image-style-align-left\" style=\"width:9%;\">' + \\\n",
    "                            '<img src=\"/openbis/openbis/file-service/eln-lims/30/77/c8/3077c8f8-0e55-41e5-9021-7ed43863e5a4/cc44149e-b2d4-4850-9f88-7a4cd54c1a66.png\">' + \\\n",
    "                            '</figure><p><br>Lammps simulation using pyiron for energy minimization/structural optimization.<br>&nbsp;</p><p><span style=\"color:hsl(240,75%,60%);\">' + \\\n",
    "                            '<strong>Scroll down below other properties to view conceptual dictionary with ontological ids of selected properties and values.</strong></span>' + \\\n",
    "                            '</p><p>The conceptual dictionary is in JSON-LD format. Learn more about it <a href=\"https://www.w3.org/ns/json-ld/\">here</a><br>&nbsp;</p>'\n",
    "\n",
    "        atom_ionic_min_algo = None\n",
    "        if cdict['minimization_algorithm'] == 'fire':\n",
    "            atom_ionic_min_algo = ('MIN_ALGO_FIRE').lower()\n",
    "\n",
    "        json_file = cdict['project_name'] + '/' + cdict['job_name'] + '_concept_dict.json'\n",
    "        with open(json_file, 'r') as file:\n",
    "            json_string = file.read()\n",
    "        json_string = format_json_string(json_string)\n",
    "\n",
    "        props_dict = {\n",
    "            '$name': cdict['job_name'],\n",
    "            'description': description,\n",
    "            'workflow_manager': cdict['workflow_manager'],\n",
    "            'bam_username': user,\n",
    "            'sim_job_finished': job_status,\n",
    "            'start_date': cdict['job_stoptime'],\n",
    "            'sim_walltime_in_hours': delta.total_seconds()/3600,\n",
    "            'sim_coretime_in_hours': cdict['sim_coretime_hours'],\n",
    "            'ncores': cdict['number_cores'],\n",
    "            'atomistic_calc_type': atom_calc_type,\n",
    "            'periodic_boundary_x': cdict['periodicity_in_x'],\n",
    "            'periodic_boundary_y': cdict['periodicity_in_y'],\n",
    "            'periodic_boundary_z': cdict['periodicity_in_z'],\n",
    "            'atom_cell_vol_relax': True if 'http://purls.helmholtz-metadaten.de/asmo/CellVolumeRelaxation' in cdict['dof'] else False,\n",
    "            'atom_cell_shp_relax': True if 'CellShapeRelaxation' in cdict['dof'] else False,\n",
    "            'atom_pos_relax': True if 'http://purls.helmholtz-metadaten.de/asmo/AtomicPositionRelaxation' in cdict['dof'] else False,\n",
    "            'atom_ionic_min_algo': atom_ionic_min_algo,\n",
    "            'max_iters': cdict['maximum iterations'],\n",
    "            'atom_e_tol_ion_in_ev': cdict['ionic energy tolerance'],\n",
    "            'atom_f_tol_in_ev_a': cdict['force tolerance'],\n",
    "            'atom_ionic_steps': cdict['NumberIonicSteps'],\n",
    "            'atom_fin_tot_eng_in_ev': cdict['FinalTotalEnergy'],\n",
    "            'atom_fin_vol_in_a3': cdict['FinalTotalVolume'],\n",
    "            'atom_fin_pot_eng_in_ev': cdict['FinalPotentialEnergy'],\n",
    "            'atom_force_max_in_ev_a': cdict['FinalMaximumForce'],\n",
    "            'conceptual_dictionary': json_string,\n",
    "        }\n",
    "    \n",
    "        object_ = o.new_object(\n",
    "            type       = 'PYIRON_JOB.LAMMPS',\n",
    "            space      = space,\n",
    "            experiment = '/' + space + '/' + project + '/' + collection,\n",
    "            props      = props_dict\n",
    "        )\n",
    "        object_.save()\n",
    "\n",
    "        #hdf_ver = job.to_dict()['HDF_VERSION']\n",
    "        path_to_h5 = cdict['project_name'] + '/' + str(cdict['job_name']) + '.h5'\n",
    "        path_to_json = cdict['project_name'] + '/' + str(cdict['job_name']) + '_concept_dict.json'\n",
    "        path_to_yml = cdict['project_name'] + '/' + str(cdict['job_name']) + '_environment.yml'\n",
    "        \n",
    "        dataset_props_dict = {\n",
    "            '$name': cdict['job_name'] + '.h5',\n",
    "            'production_date': datetime.strptime(cdict['job_stoptime'], \"%Y-%m-%d %H:%M:%S\").date().strftime(\"%Y-%m-%d\"),\n",
    "            'file_format': 'HDF5',\n",
    "            #'hdf5_version': hdf_ver,\n",
    "            'reference': 'https://github.com/pyiron/pyiron_atomistics/blob/main/pyiron_atomistics/lammps/base.py',\n",
    "        }\n",
    "        \n",
    "        ds_hdf = o.new_dataset(\n",
    "            type       = 'PYIRON_JOB',\n",
    "            collection = '/' + space + '/' + project + '/' + collection,\n",
    "            object     = object_,\n",
    "            files      = [path_to_h5],\n",
    "            props      = dataset_props_dict\n",
    "        )\n",
    "\n",
    "        ds_hdf.save()\n",
    "\n",
    "        ds_json = o.new_dataset(\n",
    "            type       = 'ATTACHMENT',\n",
    "            collection = '/' + space + '/' + project + '/' + collection,\n",
    "            object     = object_,\n",
    "            files      = [path_to_json],\n",
    "            props      = {'$name':cdict['job_name']+'_concept_dict.json'}\n",
    "        )\n",
    "\n",
    "        ds_json.save()\n",
    "\n",
    "        ds_yml = o.new_dataset(\n",
    "            type       = 'COMP_ENV',\n",
    "            collection = '/' + space + '/' + project + '/' + collection,\n",
    "            object     = object_,\n",
    "            files      = [path_to_yml],\n",
    "            props      = {'$name':cdict['job_name']+'_environment.yml', 'env_tool': 'conda'}\n",
    "        )\n",
    "\n",
    "        ds_yml.save()\n",
    "\n",
    "        if struct_concept_dict != None:\n",
    "            struct_object_name = 'input_structure_' + flatten_crystal_cdict(struct_concept_dict)['job_name']\n",
    "            objects_1 = o.get_objects(\n",
    "                space      = space,\n",
    "                type       ='MAT_SIM_STRUCTURE.CRYSTAL',\n",
    "                start_with = 0,\n",
    "            )\n",
    "            exists = False\n",
    "            for object_1 in objects_1:\n",
    "                if object_1.p.get('$name') == struct_object_name:\n",
    "                    exists = True\n",
    "                    found_object_1 = object_1\n",
    "\n",
    "            if exists == True:\n",
    "                object_.set_parents(found_object_1.identifier)\n",
    "                object_.save()\n",
    "            else:\n",
    "                print(\"==============================\\n\")\n",
    "                print(\"Create structure object first!\\n\")\n",
    "                print(\"==============================\\n\")\n",
    "        \n",
    "        return object_.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a75afd2-ed73-40cb-9f3d-28e9da34db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LAMMPS specific functions for parsing\n",
    "\n",
    "Use this a reference for specific implementations\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "def process_structure_crystal(job, initial_structure = None, rotation_indices = None):\n",
    "    sample_dict = {}\n",
    "    add_contexts(sample_dict)\n",
    "    get_chemical_species(job, sample_dict)\n",
    "    get_simulation_cell(job, sample_dict)\n",
    "    add_sample_software(job, sample_dict)\n",
    "    get_simulation_folder(job, sample_dict)\n",
    "    return sample_dict\n",
    "\n",
    "def add_contexts(sample_dict):\n",
    "    sample_dict['@context'] = {}\n",
    "    sample_dict['@context']['path'] = 'http://purls.helmholtz-metadaten.de/cmso/hasPath'\n",
    "    sample_dict['@context']['unit_cell'] = 'http://purls.helmholtz-metadaten.de/cmso/UnitCell'\n",
    "    sample_dict['@context']['atoms'] = 'http://purls.helmholtz-metadaten.de/cmso/Atom'\n",
    "    sample_dict['@context']['molecules'] = 'http://purls.helmholtz-metadaten.de/cmso/Molecule'\n",
    "    sample_dict['@context']['bravais_lattice'] = 'http://purls.helmholtz-metadaten.de/cmso/hasBravaisLattice'\n",
    "    sample_dict['@context']['chemical_species'] = 'http://purls.helmholtz-metadaten.de/cmso/ChemicalSpecies'\n",
    "    sample_dict['@context']['simulation_cell'] = 'http://www.w3.org/2000/01/rdf-schema#label'\n",
    "    sample_dict['@context']['label'] = 'http://www.w3.org/2000/01/rdf-schema#label'\n",
    "    sample_dict['@context']['unit'] = 'http://purls.helmholtz-metadaten.de/cmso/hasUnit'\n",
    "    sample_dict['@context']['value'] = 'http://purls.helmholtz-metadaten.de/asmo/hasValue'\n",
    "    sample_dict['@context']['vector'] = 'http://purls.helmholtz-metadaten.de/cmso/Vector'\n",
    "    #method_dict['@context']['workflow_manager'] = ''\n",
    "    #method_dict['@context']['software'] = ''\n",
    "\n",
    "\n",
    "def get_simulation_folder(job, sample_dict):\n",
    "    sample_dict['path'] = os.path.join(job.project.path, f'{job.name}_hdf5')\n",
    "\n",
    "def identify_unit_cell(job, sample_dict):\n",
    "    #Stuff lattice quantities and orientation\n",
    "    return\n",
    "\n",
    "def identify_crystal_structure(job, sample_dict):\n",
    "    #Stuff here for space group and bravais lattice\n",
    "    return\n",
    "\n",
    "def get_chemical_species(job, sample_dict):\n",
    "    structure = job.structure\n",
    "    natoms = structure.get_number_of_atoms()\n",
    "    species_dict = dict(structure.get_number_species_atoms())\n",
    "    atoms_list = []\n",
    "    for k in species_dict.keys():\n",
    "        element = {}\n",
    "        element[\"value\"] = species_dict[k]\n",
    "        element[\"label\"] = k\n",
    "        atoms_list.append(element)\n",
    "\n",
    "    atoms_list.append({'value': natoms, 'label': 'total_number_atoms'})\n",
    "        \n",
    "    sample_dict['atoms'] = atoms_list\n",
    "\n",
    "def get_simulation_cell(job, sample_dict):\n",
    "    structure = job.structure\n",
    "    cell_lengths = str([structure.cell.cellpar()[0],structure.cell.cellpar()[1],structure.cell.cellpar()[2]])\n",
    "    cell_vectors = str([structure.cell[0],structure.cell[1],structure.cell[2]])\n",
    "    cell_angles = str([structure.cell.cellpar()[3],structure.cell.cellpar()[4],structure.cell.cellpar()[5]])\n",
    "    cell_volume = structure.get_volume()\n",
    "    \n",
    "    simulation_cell_details = []\n",
    "\n",
    "    cell_lengths_dict = {}\n",
    "    cell_lengths_dict[\"value\"] = cell_lengths\n",
    "    cell_lengths_dict[\"unit\"] = \"ANGSTROM\"\n",
    "    cell_lengths_dict[\"label\"] = 'simulation_cell_lengths'\n",
    "    cell_lengths_dict[\"@id\"] = \"http://purls.helmholtz-metadaten.de/cmso/hasLength\"\n",
    "    simulation_cell_details.append(cell_lengths_dict)\n",
    "    \n",
    "    cell_vector_dict = {}\n",
    "    cell_vector_dict[\"value\"] = cell_vectors\n",
    "    cell_vector_dict[\"unit\"] = \"ANGSTROM\"\n",
    "    cell_vector_dict[\"label\"] = 'simulation_cell_vectors'\n",
    "    cell_vector_dict[\"@id\"] = \"http://purls.helmholtz-metadaten.de/cmso/hasVector\"\n",
    "    simulation_cell_details.append(cell_vector_dict)\n",
    "\n",
    "    cell_angles_dict = {}\n",
    "    cell_angles_dict[\"value\"] = cell_angles\n",
    "    cell_angles_dict[\"unit\"] = \"DEGREES\"\n",
    "    cell_angles_dict[\"label\"] = 'simulation_cell_angles'\n",
    "    cell_angles_dict[\"@id\"] = \"http://purls.helmholtz-metadaten.de/cmso/hasAngle\"\n",
    "    simulation_cell_details.append(cell_angles_dict)\n",
    "\n",
    "    cell_volume_dict = {}\n",
    "    cell_volume_dict[\"value\"] = np.round(cell_volume, decimals=4)\n",
    "    cell_volume_dict[\"unit\"] = \"ANGSTROM3\"\n",
    "    cell_volume_dict[\"label\"] = 'simulation_cell_volume'\n",
    "    cell_volume_dict[\"@id\"] = \"http://purls.helmholtz-metadaten.de/cmso/hasVolume\"\n",
    "    simulation_cell_details.append(cell_volume_dict)\n",
    "\n",
    "    sample_dict['simulation_cell'] = simulation_cell_details\n",
    "\n",
    "def add_sample_software(job, sample_dict):\n",
    "    sample_dict[\"workflow_manager\"] = {}\n",
    "    sample_dict[\"workflow_manager\"][\"@id\"] = \"http://demo.fiz-karlsruhe.de/matwerk/E457491\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        output1 = subprocess.check_output(['grep', 'pyiron_atomistics', job.project.name + '/' + job.name + '_environment.yml'])\n",
    "        s1 = str((output1.decode('utf-8')))\n",
    "    except:\n",
    "        s1 = ''\n",
    "    try:     \n",
    "        output2 = subprocess.check_output(['grep', 'pyiron_workflow', job.project.name + '/' + job.name + '_environment.yml'])\n",
    "        s2 = str((output2.decode('utf-8')))\n",
    "    except:\n",
    "        s2 = ''\n",
    "    hdf_ver = job.to_dict()['HDF_VERSION']\n",
    "    st = 'p' + s1.split('=')[0].split('p')[1] + \"=\" + s1.split('=')[1] + ', ' + 'p' + s2.split('=')[0].split('p')[1] + \"=\" + s2.split('=')[1] #+ ', pyiron_HDF_version=' + hdf_ver\n",
    "    sample_dict[\"workflow_manager\"][\"label\"] = st\n",
    "    \n",
    "    pyiron_job_details = []\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"job_name\",\n",
    "            \"value\": job.name,\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"project_name\",\n",
    "            \"value\": job.project.name,\n",
    "        }\n",
    "    )\n",
    "    sample_dict[\"job_details\"] = pyiron_job_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5cad282-0e43-42a2-8ad6-75ce3621db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LAMMPS specific functions for parsing\n",
    "\n",
    "Use this a reference for specific implementations\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "def process_lammps_job(job):\n",
    "    method_dict = {}\n",
    "    add_contexts(method_dict)\n",
    "    #get_structures(job, method_dict)\n",
    "    identify_method(job, method_dict)\n",
    "    extract_calculated_quantities(job, method_dict)\n",
    "    add_software(job, method_dict)\n",
    "    #add_pyiron_details(job, method_dict)\n",
    "    #add_sim_details(job, method_dict)\n",
    "    get_simulation_folder(job, method_dict)\n",
    "    return method_dict\n",
    "\n",
    "def add_contexts(method_dict):\n",
    "    method_dict['@context'] = {}\n",
    "    method_dict['@context']['sample'] = 'http://purls.helmholtz-metadaten.de/cmso/AtomicScaleSample'\n",
    "    method_dict['@context']['path'] = 'http://purls.helmholtz-metadaten.de/cmso/hasPath'\n",
    "    method_dict['@context']['dof'] = 'http://purls.helmholtz-metadaten.de/asmo/hasRelaxationDOF'\n",
    "    method_dict['@context']['inputs'] = 'http://purls.helmholtz-metadaten.de/asmo/hasInputParameter'\n",
    "    method_dict['@context']['label'] = 'http://www.w3.org/2000/01/rdf-schema#label'\n",
    "    method_dict['@context']['unit'] = 'http://purls.helmholtz-metadaten.de/asmo/hasUnit'\n",
    "    method_dict['@context']['value'] = 'http://purls.helmholtz-metadaten.de/asmo/hasValue'\n",
    "    method_dict['@context']['outputs'] = 'http://purls.helmholtz-metadaten.de/cmso/hasCalculatedProperty'\n",
    "    #method_dict['@context']['workflow_manager'] = ''\n",
    "    #method_dict['@context']['software'] = ''\n",
    "    method_dict['@context']['molecular_dynamics'] = 'http://purls.helmholtz-metadaten.de/asmo/MolecularDynamics'\n",
    "    method_dict['@context']['molecular_statics'] = 'http://purls.helmholtz-metadaten.de/asmo/MolecularStatics'\n",
    "    method_dict['@context']['ensemble'] = 'http://purls.helmholtz-metadaten.de/asmo/hasStatisticalEnsemble'\n",
    "\n",
    "\n",
    "def get_simulation_folder(job, method_dict):\n",
    "    method_dict['path'] = os.path.join(job.project.path, f'{job.name}_hdf5')\n",
    "\n",
    "def get_structures(job, method_dict):\n",
    "    initial_pyiron_structure = job.structure\n",
    "    final_pyiron_structure = job.get_structure(frame=-1)\n",
    "    \n",
    "    method_dict['sample'] =  {'initial':initial_pyiron_structure, \n",
    "                            'final': final_pyiron_structure}\n",
    "\n",
    "def identify_method(job, method_dict):\n",
    "    job_dict = job.input.to_dict()\n",
    "    input_dict = {\n",
    "        job_dict[\"control_inp/data_dict\"][\"Parameter\"][x]: job_dict[\n",
    "            \"control_inp/data_dict\"\n",
    "        ][\"Value\"][x]\n",
    "        for x in range(len(job_dict[\"control_inp/data_dict\"][\"Parameter\"]))\n",
    "    }\n",
    "    dof = []\n",
    "    temp = None\n",
    "    press = None\n",
    "    md_method = None\n",
    "    ensemble = None\n",
    "\n",
    "    if \"min_style\" in input_dict.keys():\n",
    "        dof.append(\"http://purls.helmholtz-metadaten.de/asmo/AtomicPositionRelaxation\")\n",
    "        if job.input.control['fix___ensemble'] != 'all nve': dof.append(\"http://purls.helmholtz-metadaten.de/asmo/CellVolumeRelaxation\")\n",
    "        md_method = \"molecular_statics\"\n",
    "        e_tol = float(input_dict['minimize'].split()[0])\n",
    "        f_tol = float(input_dict['minimize'].split()[1])\n",
    "        maxiter = int(input_dict['minimize'].split()[2])\n",
    "\n",
    "    elif \"nve\" in input_dict[\"fix___ensemble\"]:\n",
    "        if int(input_dict[\"run\"]) == 0:\n",
    "            method = \"static\"\n",
    "            md_method = \"molecular_statics\"\n",
    "            ensemble = \"http://purls.helmholtz-metadaten.de/asmo/MicrocanonicalEnsemble\"\n",
    "\n",
    "        elif int(input_dict[\"run\"]) > 0:\n",
    "            method = \"md_nve\"\n",
    "            dof.append(\"http://purls.helmholtz-metadaten.de/asmo/AtomicPositionRelaxation\")\n",
    "            md_method = \"molecular_dynamics\"\n",
    "            ensemble = \"http://purls.helmholtz-metadaten.de/asmo/MicrocanonicalEnsemble\"\n",
    "\n",
    "    elif \"nvt\" in input_dict[\"fix___ensemble\"]:\n",
    "        method = \"md_nvt\"\n",
    "        raw = input_dict[\"fix___ensemble\"].split()\n",
    "        temp = float(raw[3])\n",
    "        dof.append(\"http://purls.helmholtz-metadaten.de/asmo/AtomicPositionRelaxation\")\n",
    "        md_method = \"molecular_dynamics\"\n",
    "        ensemble = \"http://purls.helmholtz-metadaten.de/asmo/CanonicalEnsemble\"\n",
    "\n",
    "    elif \"npt\" in input_dict[\"fix___ensemble\"]:\n",
    "        dof.append(\"http://purls.helmholtz-metadaten.de/asmo/AtomicPositionRelaxation\")\n",
    "        dof.append(\"http://purls.helmholtz-metadaten.de/asmo/CellVolumeRelaxation\")\n",
    "        if \"aniso\" in input_dict[\"fix___ensemble\"]:\n",
    "            method = \"md_npt_aniso\"\n",
    "            dof.append(\"http://purls.helmholtz-metadaten.de/asmo/CellShapeRelaxation\")\n",
    "        else:\n",
    "            method = \"md_npt_iso\"\n",
    "        md_method = \"molecular_dynamics\"\n",
    "        raw = input_dict[\"fix___ensemble\"].split()\n",
    "        temp = float(raw[3])\n",
    "        press = float(raw[7])\n",
    "        ensemble = \"http://purls.helmholtz-metadaten.de/asmo/IsothermalIsobaricEnsemble\"\n",
    "\n",
    "    method_dict[md_method] = {}\n",
    "\n",
    "    if md_method == \"molecular_statics\":\n",
    "        method_dict[md_method]['minimization_algorithm'] = input_dict['min_style']\n",
    "\n",
    "    input_dict = {\n",
    "        job_dict[\"control_inp/data_dict\"][\"Parameter\"][x]: job_dict[\n",
    "            \"control_inp/data_dict\"\n",
    "        ][\"Value\"][x]\n",
    "        for x in range(len(job_dict[\"control_inp/data_dict\"][\"Parameter\"]))\n",
    "    }\n",
    "    pb = []\n",
    "    pb.append(input_dict['boundary'])\n",
    "    if (pb[0][0] == \"p\"):\n",
    "        method_dict[md_method]['periodicity_in_x'] = True\n",
    "    else:\n",
    "        method_dict[md_method]['periodicity_in_x'] = False\n",
    "    if (pb[0][2] == \"p\"):\n",
    "        method_dict[md_method]['periodicity_in_y'] = True\n",
    "    else:\n",
    "        method_dict[md_method]['periodicity_in_y'] = False\n",
    "    if (pb[0][4] == \"p\"):\n",
    "        method_dict[md_method]['periodicity_in_z'] = True\n",
    "    else:\n",
    "        method_dict[md_method]['periodicity_in_z'] = False\n",
    "\n",
    "    method_dict[md_method]['inputs'] = []\n",
    "\n",
    "    temperature = {}\n",
    "    temperature[\"value\"] = temp\n",
    "    temperature[\"unit\"] = \"K\"\n",
    "    temperature[\"label\"] = \"temperature\"\n",
    "\n",
    "    method_dict[md_method]['inputs'].append(temperature)\n",
    "\n",
    "    pressure = {}\n",
    "    pressure[\"value\"] = press\n",
    "    pressure[\"unit\"] = \"GigaPA\"\n",
    "    pressure[\"label\"] = \"pressure\"\n",
    "\n",
    "    method_dict[md_method]['inputs'].append(pressure)\n",
    "\n",
    "    energy_tol = {}\n",
    "    energy_tol[\"value\"] = e_tol\n",
    "    energy_tol[\"unit\"] = \"EV\"\n",
    "    energy_tol[\"label\"] = \"ionic energy tolerance\"\n",
    "\n",
    "    method_dict[md_method]['inputs'].append(energy_tol)\n",
    "\n",
    "    force_tol = {}\n",
    "    force_tol[\"value\"] = f_tol\n",
    "    force_tol[\"unit\"] = \"EV/ANGSTROM\"\n",
    "    force_tol[\"label\"] = \"force tolerance\"\n",
    "\n",
    "    method_dict[md_method]['inputs'].append(force_tol)\n",
    "\n",
    "    maximum_iterations = {}\n",
    "    maximum_iterations[\"value\"] = maxiter\n",
    "    maximum_iterations[\"label\"] = \"maximum iterations\"\n",
    "\n",
    "    method_dict[md_method]['inputs'].append(maximum_iterations)\n",
    "\n",
    "    method_dict[md_method][\"ensemble\"] = ensemble\n",
    "    \n",
    "    method_dict[\"dof\"] = dof\n",
    "\n",
    "\n",
    "    # now process potential\n",
    "    inpdict = job.input.to_dict()\n",
    "    ps = inpdict[\"potential_inp/data_dict\"][\"Value\"][0]\n",
    "    name = inpdict[\"potential_inp/potential/Name\"]\n",
    "    potstr = job.input.to_dict()[\"potential_inp/potential/Citations\"]\n",
    "    potdict = ast.literal_eval(potstr[1:-1])\n",
    "    url = None\n",
    "    if \"url\" in potdict[list(potdict.keys())[0]].keys():\n",
    "        url = potdict[list(potdict.keys())[0]][\"url\"]\n",
    "\n",
    "    if 'meam' in ps:\n",
    "        method_dict['@context']['potential'] = \"http://purls.helmholtz-metadaten.de/asmo/ModifiedEmbeddedAtomModel\"\n",
    "    elif 'eam' in ps:\n",
    "        method_dict['@context']['potential'] = \"http://purls.helmholtz-metadaten.de/asmo/EmbeddedAtomModel\"\n",
    "    elif 'lj' in ps:\n",
    "        method_dict['@context']['potential'] = \"http://purls.helmholtz-metadaten.de/asmo/LennardJonesPotential\"\n",
    "    elif 'ace' in ps:\n",
    "        method_dict['@context']['potential'] = \"http://purls.helmholtz-metadaten.de/asmo/MachineLearningPotential\"\n",
    "    else:\n",
    "        method_dict['@context']['potential'] = \"http://purls.helmholtz-metadaten.de/asmo/InteratomicPotential\"\n",
    "\n",
    "\n",
    "    method_dict[md_method][\"potential\"] = {}\n",
    "    method_dict[md_method][\"potential\"][\"label\"] = name\n",
    "    if url is not None:\n",
    "        method_dict[md_method][\"potential\"][\"@id\"] = url\n",
    "\n",
    "def add_software(job, method_dict):\n",
    "    method_dict[\"workflow_manager\"] = {}\n",
    "    method_dict[\"workflow_manager\"][\"@id\"] = \"http://demo.fiz-karlsruhe.de/matwerk/E457491\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        output1 = subprocess.check_output(['grep', 'pyiron_atomistics', job.project.name + '/' + job.name + '_environment.yml'])\n",
    "        s1 = str((output1.decode('utf-8')))\n",
    "    except:\n",
    "        s1 = ''\n",
    "    try:     \n",
    "        output2 = subprocess.check_output(['grep', 'pyiron_workflow', job.project.name + '/' + job.name + '_environment.yml'])\n",
    "        s2 = str((output2.decode('utf-8')))\n",
    "    except:\n",
    "        s2 = ''\n",
    "    hdf_ver = job.to_dict()['HDF_VERSION']\n",
    "    st = 'p' + s1.split('=')[0].split('p')[1] + \"=\" + s1.split('=')[1] + ', ' + 'p' + s2.split('=')[0].split('p')[1] + \"=\" + s2.split('=')[1] #+ ', pyiron_HDF_version=' + hdf_ver\n",
    "    method_dict[\"workflow_manager\"][\"label\"] = st\n",
    "\n",
    "    pyiron_job_details = []\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"job_name\",\n",
    "            \"value\": job.name,\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"project_name\",\n",
    "            \"value\": job.project.name,\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"job_type\",\n",
    "            \"value\": job.database_entry.hamilton,\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"job_status\",\n",
    "            \"value\": str(job.status),\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"job_starttime\",\n",
    "            \"value\": str(job.database_entry.timestart.strftime(\"%Y-%m-%d %H:%M:%S\")),\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"job_stoptime\",\n",
    "            \"value\": str(job.database_entry.timestop.strftime(\"%Y-%m-%d %H:%M:%S\")),\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"sim_coretime_hours\",\n",
    "            \"value\": job.database_entry.totalcputime,\n",
    "        }\n",
    "    )\n",
    "    pyiron_job_details.append(\n",
    "        {\n",
    "            \"label\": \"number_cores\",\n",
    "            \"value\": job.to_dict()['server']['cores'],\n",
    "        }\n",
    "    )\n",
    "    method_dict[\"job_details\"] = pyiron_job_details\n",
    "    # and finally code details\n",
    "\n",
    "    software = {\n",
    "        \"@id\": \"http://demo.fiz-karlsruhe.de/matwerk/E447986\",\n",
    "        \"label\": \"LAMMPS \" + job.to_dict()['executable']['version'],\n",
    "    }\n",
    "    method_dict[\"software\"] = [software]\n",
    "\n",
    "def extract_calculated_quantities(job, method_dict):\n",
    "    \"\"\"\n",
    "    Extracts calculated quantities from a job.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    job : pyiron.Job\n",
    "        The job object containing the calculated quantities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of dictionaries, each containing the label, value, unit, and associate_to_sample of a calculated quantity.\n",
    "\n",
    "    \"\"\"\n",
    "    aen = np.mean(job.output.energy_tot)\n",
    "    fen = job.output.energy_tot[-1]\n",
    "    fpe = job.output.energy_tot[-1]\n",
    "    avol = np.mean(job.output.volume)\n",
    "    fvol = job.output.volume[-1]\n",
    "    fmax = job.output.force_max[-1]\n",
    "    nionic = len(job.output.steps)-1\n",
    "    outputs = []\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"AverageTotalEnergy\",\n",
    "            \"value\": np.round(aen, decimals=4),\n",
    "            \"unit\": \"EV\",\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"FinalTotalEnergy\",\n",
    "            \"value\": np.round(fen, decimals=4),\n",
    "            \"unit\": \"EV\",\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"FinalPotentialEnergy\",\n",
    "            \"value\": np.round(fpe, decimals=4),\n",
    "            \"unit\": \"EV\",\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"AverageTotalVolume\",\n",
    "            \"value\": np.round(avol, decimals=4),\n",
    "            \"unit\": \"ANGSTROM3\",\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"FinalTotalVolume\",\n",
    "            \"value\": np.round(fvol, decimals=4),\n",
    "            \"unit\": \"ANGSTROM3\",\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"FinalMaximumForce\",\n",
    "            \"value\": np.round(fmax, decimals=16),\n",
    "            \"unit\": \"EV/ANGSTROM\",\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"label\": \"NumberIonicSteps\",\n",
    "            \"value\": nionic,\n",
    "        }\n",
    "    )\n",
    "    method_dict['outputs'] =  outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d1c95da-eec6-4cff-aace-0377d857ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_lammps_cdict(cdict):\n",
    "        flat = {}\n",
    "        for k, v in cdict.items():\n",
    "            if k != '@context':\n",
    "                if isinstance(v, dict):\n",
    "                    if 'label' in v.keys():\n",
    "                        flat[k] = v['label']\n",
    "                    else:\n",
    "                        flat = flat | flatten_cdict(v)\n",
    "                elif k == 'inputs' or k == 'outputs' or k == 'job_details':\n",
    "                    for i in v:\n",
    "                        flat[i['label']] = i['value']\n",
    "                elif k == 'software':\n",
    "                    flat[k] = v[0]['label']\n",
    "                else:\n",
    "                    flat[k] = v\n",
    "        return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa881aa5-c32a-4f0c-bba2-53faafed5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_crystal_cdict(cdict):\n",
    "        flat = {}\n",
    "        for k, v in cdict.items():\n",
    "            if k != '@context':\n",
    "                if isinstance(v, dict):\n",
    "                    if 'label' in v.keys():\n",
    "                        flat[k] = v['label']\n",
    "                    else:\n",
    "                        flat = flat | flatten_cdict(v)\n",
    "                elif k == 'atoms' or k == 'simulation_cell' or k == 'job_details':\n",
    "                    for i in v:\n",
    "                        flat[i['label']] = i['value']\n",
    "                elif k == 'software':\n",
    "                    flat[k] = v[0]['label']\n",
    "                else:\n",
    "                    flat[k] = v\n",
    "        return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a325af8-9f0a-4d4d-abff-f6e857e0014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json_string(json_string):\n",
    "    json_string = json_string.replace('\\n', '<br>')\n",
    "    result = []\n",
    "    for index, char in enumerate(json_string):\n",
    "        if char == \" \" and (index == 0 or json_string[index - 1] != \":\"):\n",
    "            result.append(\"&nbsp;&nbsp;\")\n",
    "        else:\n",
    "            result.append(char)\n",
    "\n",
    "    json_string = \"\".join(result)\n",
    "    return json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c2df9-aaba-402f-9cc3-31ad61a3a65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb8814-9eb3-4a5a-bec8-d47b19135e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
